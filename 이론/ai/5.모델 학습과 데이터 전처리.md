## 문제 1 (난이도: 쉬움)
다음 중 머신러닝 모델 학습을 위해 데이터를 훈련 데이터와 테스트 데이터로 분리하는 가장 주된 이유는 무엇인가?

### 보기
A. 모델의 학습 속도를 높이기 위해
B. 데이터의 양을 줄여 메모리 사용량을 최적화하기 위해
C. 모델이 학습 데이터에만 과적합되었는지 여부를 객관적으로 평가하기 위해
D. 데이터의 전처리 과정을 생략하기 위해
E. 모든 데이터를 모델 학습에 사용하여 성능을 극대화하기 위해

**정답:** C
**해설:** 데이터를 훈련 데이터와 테스트 데이터로 분리하는 핵심 이유는 모델이 학습 과정에서 보지 못한 새로운 데이터(테스트 데이터)에 대해 얼마나 좋은 성능을 내는지, 즉 일반화 성능을 측정하기 위함입니다. 이를 통해 과적합 여부를 판단할 수 있습니다.
- A, B, D는 주된 이유가 아니며, E는 과적합을 유발하는 위험한 방법입니다.

---

## 문제 2 (난이도: 보통)
모델의 과적합(Overfitting) 상태에 대한 설명으로 가장 옳은 것은?

### 보기
A. 훈련 데이터와 테스트 데이터 모두에서 낮은 성능을 보인다.
B. 모델이 너무 단순하여 데이터의 기본 패턴조차 학습하지 못했다.
C. 훈련 데이터에서는 높은 성능을 보이지만, 테스트 데이터에서는 현저히 낮은 성능을 보인다.
D. 데이터의 양이 많을수록 항상 과적합이 발생한다.
E. 데이터의 특성(feature)이 적을수록 항상 과적합이 발생한다.

**정답:** C
**해설:** 과적합은 모델이 훈련 데이터에 너무 익숙해져서 노이즈까지 학습한 상태를 말합니다. 이로 인해 훈련 데이터에 대한 예측 성능은 높지만, 새로운 데이터(테스트 데이터)에 대한 일반화 성능은 떨어지는 현상이 나타납니다.
- A, B는 과소적합(Underfitting)에 대한 설명입니다.
- D, E는 과적합에 영향을 줄 수 있는 요인이지만 항상 그렇지는 않습니다.

---

## 문제 3 (난이도: 보통)
데이터 전처리 기법 중 표준화(Standardization)에 대한 설명으로 옳지 않은 것은?

### 보기
A. 데이터의 평균을 0, 표준편차를 1로 변환하는 방법이다.
B. 모든 특성(feature)이 모델에 공평한 영향력을 행사하도록 스케일을 조정한다.
C. 일반적으로 이상치(outlier)에 민감하게 반응하는 정규화(Normalization)에 비해 덜 민감하다.
D. 테스트 데이터를 표준화할 때는 테스트 데이터 자체의 평균과 표준편차를 사용해야 한다.
E. 데이터가 정규분포를 따를 때 특히 효과적인 스케일링 기법이다.

**정답:** D
**해설:** 매우 중요한 규칙으로, 테스트 데이터를 표준화할 때는 **훈련 데이터로 계산된 평균과 표준편차**를 동일하게 적용해야 합니다. 이는 훈련 과정과 테스트 과정의 데이터 분포를 일관성 있게 유지하여 모델이 안정적으로 예측하도록 하기 위함입니다. 테스트 데이터의 통계량을 사용하면 데이터 유출(Data Leakage)이 발생합니다.
- A, B, C, E는 모두 표준화의 올바른 특징입니다.

---

## 문제 4 (난이도: 쉬움)
다음 중 데이터 스케일링 기법인 정규화(Normalization)의 특징으로 옳은 것은?

### 보기
A. 데이터의 분포를 평균 0, 표준편차 1로 맞춘다.
B. 데이터의 값을 일반적으로 0과 1 사이의 범위로 축소시킨다.
C. 이상치(outlier)의 영향을 거의 받지 않는다.
D. 데이터의 최소값과 최대값을 몰라도 적용할 수 있다.
E. 데이터가 특정 클래스에 편중되었을 때 사용하는 기법이다.

**정답:** B
**해설:** 정규화는 데이터의 모든 값을 0과 1 사이의 범위로 비례적으로 축소하는 스케일링 방법입니다. 공식은 (X - min) / (max - min) 입니다.
- A는 표준화(Standardization)에 대한 설명입니다.
- C: 최소값과 최대값을 사용하므로 이상치에 매우 민감합니다.
- D: 최소값과 최대값을 알아야만 계산할 수 있습니다.
- E는 데이터 불균형 문제와 관련된 설명으로, 스케일링과는 다릅니다.

---

## 문제 5 (난이도: 보통)
`train_test_split` 함수에서 `stratify=y` 옵션을 사용하는 주된 이유는 무엇인가?

### 보기
A. 훈련 데이터와 테스트 데이터의 개수를 정확히 동일하게 맞추기 위해
B. 데이터 분리 과정을 더 빠르게 처리하기 위해
C. 원본 데이터의 클래스(레이블) 비율을 훈련 데이터와 테스트 데이터에서 동일하게 유지하기 위해
D. 데이터를 무작위로 섞지 않고 순서대로 분리하기 위해
E. 회귀(Regression) 문제에서만 사용하기 위해

**정답:** C
**해설:** `stratify=y` 옵션은 분류(Classification) 문제에서 각 클래스(레이블 `y`)가 가진 비율을 원본 데이터셋과 동일하게 훈련 데이터와 테스트 데이터에 나누어 담는 역할을 합니다. 예를 들어, 원본 데이터에 A클래스가 70%, B클래스가 30% 있다면, 분리된 훈련/테스트 데이터셋 모두 이 비율을 유지하게 됩니다. 이는 모델이 각 클래스를 공평하게 학습하고 평가받도록 보장합니다.
- A, B, D는 해당 옵션의 기능이 아닙니다.
- E: 주로 분류 문제에서 사용됩니다.

---

## 문제 6 (난이도: 보통)
모델이 훈련 데이터와 테스트 데이터 모두에서 낮은 성능을 보이며, 데이터의 복잡한 패턴을 제대로 학습하지 못하는 현상은 무엇인가?

### 보기
A. 과적합 (Overfitting)
B. 과소적합 (Underfitting)
C. 데이터 유출 (Data Leakage)
D. 일반화 (Generalization)
E. 데이터 증강 (Data Augmentation)

**정답:** B
**해설:** 과소적합은 모델이 너무 단순하여 훈련 데이터에 존재하는 핵심적인 패턴조차 제대로 학습하지 못한 상태를 의미합니다. 이로 인해 훈련 데이터에 대한 성능도 낮고, 당연히 테스트 데이터에 대한 성능도 낮게 나타납니다.
- A: 과적합은 훈련 데이터 성능은 높고 테스트 데이터 성능은 낮은 경우입니다.
- C: 훈련 단계에서 사용되어서는 안 될 정보가 모델에 노출되는 것입니다.
- D: 모델이 새로운 데이터에 대해 정확하게 예측하는 능력입니다.
- E: 훈련 데이터의 양을 늘리는 기법입니다.

---

## 문제 7 (난이도: 보통)
최근 AI 모델, 특히 딥러닝 모델에서 과적합을 방지하기 위해 사용되는 기법으로 가장 거리가 먼 것은? (2024년 AI 트렌드 참고)

### 보기
A. 드롭아웃 (Dropout)
B. 데이터 증강 (Data Augmentation)
C. 조기 종료 (Early Stopping)
D. 모델의 복잡도 증가 (Increasing Model Complexity)
E. L1/L2 규제 (L1/L2 Regularization)

**정답:** D
**해설:** 모델의 복잡도를 불필요하게 증가시키는 것은 오히려 과적합을 유발하는 주요 원인 중 하나입니다. 더 많은 파라미터는 모델이 훈련 데이터의 노이즈까지 학습하게 만들 수 있습니다. 과적합을 방지하기 위해서는 모델의 복잡도를 데이터에 맞게 적절히 조절해야 합니다.
- A, B, C, E는 모두 과적합을 완화하기 위해 널리 사용되는 대표적인 기법들입니다.

---

## 문제 8 (난이도: 쉬움)
데이터 전처리 시 스케일링(Scaling)을 수행하는 이유로 가장 적절한 것은?

### 보기
A. 데이터의 결측치를 제거하기 위해
B. 텍스트 데이터를 숫자 데이터로 변환하기 위해
C. 각 특성(feature)의 단위와 값의 범위가 달라 발생하는 모델의 왜곡을 방지하기 위해
D. 데이터의 차원을 축소하여 계산 효율성을 높이기 위해
E. 데이터의 이상치를 인위적으로 추가하기 위해

**정답:** C
**해설:** 데이터의 여러 특성들은 각기 다른 단위(예: 키(cm), 몸무게(kg), 나이(세))와 값의 범위를 가집니다. 이 차이가 모델 학습 시 특정 특성에만 가중치가 쏠리는 현상을 유발할 수 있습니다. 스케일링은 모든 특성의 값을 비슷한 범위로 조정하여 모델이 모든 특성을 공평하게 학습하도록 돕습니다.
- A, B, D, E는 스케일링의 목적이 아닙니다.

---

## 문제 9 (난이도: 보통)
다음 중 표준화(Standardization)와 정규화(Normalization)에 대한 설명으로 옳은 것을 모두 고르시오.

가. 표준화는 이상치에 덜 민감하고, 정규화는 이상치에 더 민감하다.
나. 표준화는 데이터의 분포를 정규분포로 바꾸는 역할을 한다.
다. 정규화는 항상 표준화보다 우수한 성능을 보장한다.
라. 두 기법 모두 거리 기반 알고리즘(예: k-NN, SVM)의 성능에 영향을 줄 수 있다.

### 보기
A. 가, 나
B. 가, 라
C. 나, 다
D. 다, 라
E. 가, 나, 라

**정답:** B
**해설:** 
- **가:** 표준화는 평균과 표준편차를 사용하므로 이상치의 영향을 덜 받지만, 정규화는 최소/최대값을 직접 사용하므로 이상치가 존재할 경우 값의 범위가 크게 왜곡될 수 있어 민감합니다. (옳음)
- **나:** 표준화는 데이터의 평균을 0, 표준편차를 1로 만들 뿐, 원래 데이터의 분포 형태 자체를 정규분포로 바꾸지는 않습니다. (틀림)
- **다:** 어떤 스케일링 기법이 더 우수한지는 데이터의 특성과 사용하려는 모델에 따라 다르며, 항상 정규화가 우수하다고 말할 수 없습니다. (틀림)
- **라:** k-NN, SVM 등 거리 기반 알고리즘은 특성 간의 스케일 차이에 큰 영향을 받으므로, 스케일링을 통해 성능을 향상시킬 수 있습니다. (옳음)

---

## 문제 10 (난이도: 어려움)
대규모 언어 모델(LLM)을 특정 도메인에 맞게 파인튜닝(Fine-tuning)할 때, 매우 적은 양의 학습 데이터만 사용했더니 훈련 데이터에 대한 손실(loss)은 크게 감소했지만 검증(validation) 데이터에 대한 손실은 오히려 증가했다. 이 현상과 이를 해결하기 위한 방법으로 가장 적절한 것은?

### 보기
A. 현상: 과소적합, 해결책: 모델의 크기를 더 줄인다.
B. 현상: 과적합, 해결책: 학습률(learning rate)을 높이고 더 많은 에포크(epoch)를 학습시킨다.
C. 현상: 과소적합, 해결책: 더 많은 데이터를 수집하거나 데이터 증강을 적용한다.
D. 현상: 과적합, 해결책: 학습률을 낮추거나, 규제(regularization)를 강화하거나, 조기 종료(early stopping)를 적용한다.
E. 현상: 데이터 유출, 해결책: 훈련 데이터와 검증 데이터를 다시 분리한다.

**정답:** D
**해설:** 훈련 손실은 감소하지만 검증 손실이 증가하는 것은 모델이 훈련 데이터에 과적합되고 있다는 전형적인 신호입니다. 특히 적은 데이터로 파인튜닝할 때 발생하기 쉽습니다. 이를 해결하기 위해서는 모델의 학습 강도를 낮추는 방향으로 접근해야 합니다.
- **학습률 감소:** 모델이 너무 빠르게 학습하여 지역 최적점(local minima)을 지나치거나 발산하는 것을 방지합니다.
- **규제 강화:** 모델의 가중치가 너무 커지는 것을 막아 복잡도를 낮춥니다.
- **조기 종료:** 검증 손실이 더 이상 감소하지 않고 증가하기 시작하는 시점에 학습을 중단하여 과적합을 막습니다.
- B의 해결책은 과적합을 더욱 심화시킬 수 있습니다.
- A, C는 과소적합에 대한 해결책입니다.
- E는 현상에 대한 진단이 틀렸습니다.
