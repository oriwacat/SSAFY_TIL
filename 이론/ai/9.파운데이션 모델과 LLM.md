## 문제 1 (난이도: 보통)
거대 언어 모델(LLM)의 규모(데이터, 모델 크기, 학습량)가 특정 임계점을 넘어서면서, 기존에는 없던 새로운 능력이 갑자기 발현되는 현상을 무엇이라고 하는가? (예: 인-컨텍스트 학습, 추론 능력)

### 보기
A. 규모의 법칙 (Scaling Law)
B. 창발성 (Emergent Property)
C. 정렬 (Alignment)
D. 제로샷 학습 (Zero-shot Learning)
E. 전이 학습 (Transfer Learning)

**정답:** B
**해설:** 창발성(Emergent Property)은 모델의 규모가 커짐에 따라 예측하지 못했던 새로운 능력이 나타나는 현상을 의미합니다. 이는 단순히 성능이 점진적으로 향상되는 규모의 법칙과는 구분되는 개념으로, LLM이 특정 크기 이상에서 질적으로 다른 행동을 보이는 것을 설명합니다.
- A: 모델의 규모가 커질수록 성능이 예측 가능하게 향상된다는 법칙입니다.
- C: 모델의 출력을 인간의 의도와 가치에 맞추는 과정입니다.
- D, E: 특정 학습 방법을 지칭하는 용어입니다.

---

## 문제 2 (난이도: 보통)
LLM이 사실과 다르거나 지어낸 내용을 마치 정확한 정보처럼 유창하게 생성하는 현상을 '환각(Hallucination)'이라고 한다. 이 문제를 완화하기 위해, 외부의 신뢰할 수 있는 지식 소스(예: 데이터베이스, 문서)에서 관련 정보를 검색하여 답변 생성에 활용하는 기법은 무엇인가?

### 보기
A. 탈옥 (Jailbreaking)
B. 지시 학습 (Instruction Tuning)
C. 검색 증강 생성 (Retrieval-Augmented Generation, RAG)
D. 선호 학습 (Preference Learning)
E. 합성 데이터 생성 (Synthetic Data Generation)

**정답:** C
**해설:** 검색 증강 생성(RAG)은 LLM의 내부 지식에만 의존하지 않고, 질문과 관련된 정보를 외부 지식 소스에서 실시간으로 검색하여 이를 프롬프트에 포함시켜 모델에 전달합니다. 이를 통해 LLM이 더 정확하고 사실에 기반한 답변을 생성하도록 유도하여 환각 현상을 크게 줄일 수 있습니다.
- A: LLM의 안전 장치를 우회하는 기법입니다.
- B, D: LLM의 정렬(Alignment)을 위한 학습 방법입니다.
- E: 모델 학습을 위해 인공적으로 데이터를 만드는 기법입니다.

---

## 문제 3 (난이도: 보통)
ChatGPT의 핵심 기술로 알려진 RLHF(인간 피드백을 통한 강화학습)의 학습 과정에 대한 설명으로 가장 적절한 것은?

### 보기
A. 사람이 작성한 정답 데이터만으로 모델을 끝까지 학습시킨다.
B. 모델이 생성한 다양한 응답에 대해 사람이 매긴 선호도 데이터를 수집하여 '보상 모델(Reward Model)'을 학습시킨다.
C. 오직 강화학습만을 사용하여 처음부터 모델을 학습시킨다.
D. 모델의 크기를 키우는 것만으로 사람의 선호도를 자동으로 학습할 수 있다.
E. 정답이 정해진 태스크에 대해서만 적용할 수 있는 학습 방법이다.

**정답:** B
**해설:** RLHF의 핵심 아이디어는 사람의 복잡하고 주관적인 선호를 모델이 학습하도록 하는 것입니다. 이를 위해, 먼저 모델이 생성한 여러 답변에 대해 사람이 직접 순위를 매겨 선호도 데이터를 구축합니다. 그 다음, 이 데이터를 이용해 어떤 답변이 더 좋은지를 판단하는 별도의 '보상 모델'을 학습시키고, 본래의 LLM이 이 보상 모델로부터 높은 점수를 받도록 강화학습을 통해 파인튜닝하는 과정을 거칩니다.
- A, C, D, E는 RLHF의 과정이나 목적을 올바르게 설명하지 못했습니다.

---

## 문제 4 (난이도: 보통)
LLM이 텍스트를 생성할 때, 각 단계에서 가장 확률이 높은 토큰만을 선택하는 'Greedy Decoding' 방식의 가장 큰 단점은 무엇인가?

### 보기
A. 계산 비용이 너무 많이 들어 비효율적이다.
B. 생성되는 응답이 너무 다양하여 일관성이 떨어진다.
C. 매 단계의 국소적인 최적 선택이 전체적으로는 최적의 문장을 만들지 못할 수 있다.
D. 확률이 낮은 토큰은 절대 선택되지 않아 창의적인 문장 생성이 불가능하다.
E. 하이퍼파라미터(T, K, P) 설정이 너무 복잡하다.

**정답:** C
**해설:** Greedy Decoding은 각 단계에서 가장 확률 높은 토큰을 선택하는 단순하고 빠른 방법이지만, 당장의 선택이 좋아 보여도 전체 문맥상으로는 어색하거나 부자연스러운 결과를 초래할 수 있습니다. 즉, 국소 최적(local optimum)에 빠져 전역 최적(global optimum)을 놓칠 위험이 있습니다.
- A: Greedy Decoding은 계산 비용이 가장 적은 방식 중 하나입니다.
- B: 오히려 응답이 매우 결정적이고 다양성이 부족합니다.
- D: 단점이라기보다는 Greedy 방식의 특징입니다.
- E: Greedy 방식은 별도의 하이퍼파라미터가 필요 없습니다.

---

## 문제 5 (난이도: 보통)
LLM의 텍스트 생성 시, 응답의 다양성을 조절하기 위해 확률 분포를 임의로 조작하는 '샘플링(Sampling)' 기법에서 사용되는 하이퍼파라미터는 무엇인가? (이 값이 높으면 더 다양하고 창의적인 응답이, 낮으면 확률이 높은 단어 위주의 안정적인 응답이 생성된다.)

### 보기
A. K (in Top-K)
B. P (in Top-P)
C. Beam Size
D. Temperature
E. Perplexity

**정답:** D
**해설:** Temperature는 샘플링 과정에서 모델이 계산한 토큰별 확률 분포를 조절하는 역할을 합니다. Temperature 값을 높이면 전체 토큰들의 확률이 평탄화되어(비슷해져서) 확률이 낮은 토큰도 선택될 가능성이 생겨 더 다양하고 창의적인 문장이 생성됩니다. 반대로 값을 낮추면 확률이 높은 토큰에 더 집중하게 되어 결정론적이고 안정적인 문장이 생성됩니다.
- A, B: 샘플링 후보군을 제한하는 다른 방식입니다.
- C: Beam Search에서 사용하는 파라미터입니다.
- E: 언어 모델의 성능을 평가하는 지표입니다.

---

## 문제 6 (난이도: 보통)
이미지와 텍스트 같은 서로 다른 종류의 데이터를 동일한 임베딩 공간에 투영하여, 텍스트로 이미지를 검색하거나 이미지에 대한 설명을 생성하는 등 멀티모달(Multi-modal) 작업의 기반이 된 OpenAI의 모델은 무엇인가?

### 보기
A. GPT-3
B. BERT
C. ResNet
D. CLIP
E. LLaVA

**정답:** D
**해설:** CLIP(Contrastive Language-Image Pre-training)은 대규모 이미지-텍스트 쌍 데이터를 사용하여, 서로 연관된 이미지와 텍스트가 임베딩 공간에서 가깝게 위치하도록 학습하는 모델입니다. 이 공통된 임베딩 공간을 통해 텍스트와 이미지 간의 의미적 유사도를 직접 계산할 수 있게 되었고, 이는 제로샷 이미지 분류, 텍스트-이미지 검색 등 다양한 멀티모달 태스크의 기반 기술이 되었습니다.
- A, B: 언어 모델입니다.
- C: 이미지 분류 모델입니다.
- E: CLIP과 같은 모델을 기반으로 만들어진 대화형 멀티모달 모델입니다.

---

## 문제 7 (난이도: 쉬움)
LLM(거대 언어 모델)은 크게 폐쇄형과 개방형으로 나뉜다. 다음 중 LLaMA, Gemma와 같이 모델의 가중치와 구조가 대중에게 공개되어 있어 사용자가 직접 수정하거나 자신의 서버에 설치하여 사용할 수 있는 모델의 종류는 무엇인가?

### 보기
A. 개방형 LLM (Open-source LLM)
B. 폐쇄형 LLM (Closed-source LLM)
C. 정렬된 LLM (Aligned LLM)
D. 파운데이션 모델 (Foundation Model)
E. 멀티모달 모델 (Multi-modal Model)

**정답:** A
**해설:** 개방형 LLM은 모델의 구조, 학습된 가중치, 심지어 학습 코드까지 공개하여 누구나 자유롭게 접근하고 사용할 수 있도록 한 모델을 의미합니다. 이는 연구 투명성을 높이고 특정 기업에 대한 기술 종속을 줄이는 장점이 있지만, 사용자가 직접 운영하기 위한 충분한 계산 자원이 필요합니다.
- B: ChatGPT, Claude 등과 같이 API를 통해서만 사용 가능하며 내부 구조가 공개되지 않은 모델입니다.
- C, D, E는 모델의 특징이나 종류를 다른 기준으로 분류한 것입니다.
